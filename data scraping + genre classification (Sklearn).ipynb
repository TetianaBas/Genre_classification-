{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90cac35c",
   "metadata": {},
   "source": [
    "## Data scraping  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acd34540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in ./anaconda3/lib/python3.10/site-packages (4.12.2)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in ./anaconda3/lib/python3.10/site-packages (from beautifulsoup4) (2.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7df65f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4552483",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [] \n",
    "ratings=[]\n",
    "genre=[]\n",
    "year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8faf1ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.imdb.com/search/title/?title_type=tv_series&num_votes=100000,&sort=release_date,asc\"\n",
    "content = requests.get(url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ccc58d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(content,\"html.parser\")\n",
    "\n",
    "for a in soup.findAll('div', attrs={'class':'lister-item mode-advanced'}):\n",
    "    h = a.find('h3', attrs={'class':'lister-item-header'})\n",
    "    a_name=h.find('a', href=True)\n",
    "    a_rating=a.find('div', attrs={'class':'inline-block ratings-imdb-rating'})\n",
    "    a_genre=a.find('span', attrs={'class':'genre'})\n",
    "    a_year=a.find('span', attrs={'class':'lister-item-year text-muted unbold'})\n",
    "    name.append(a_name.text)\n",
    "    ratings.append(a_rating.text.strip(\"\\n\"))\n",
    "    genre.append(a_genre.text.strip(\"\\n\"))\n",
    "    year.append(a_year.text)\n",
    "\n",
    "\n",
    "df=pd.DataFrame({'Series Name' : name, 'Release Years' : year, 'Ratings' : ratings, 'Genre' : genre})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c06a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "173e4a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series Name</th>\n",
       "      <th>Release Years</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Married... with Children</td>\n",
       "      <td>(1987–1997)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Star Trek: The Next Generation</td>\n",
       "      <td>(1987–1994)</td>\n",
       "      <td>8.7</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seinfeld</td>\n",
       "      <td>(1989–1998)</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twin Peaks</td>\n",
       "      <td>(1990–1991)</td>\n",
       "      <td>8.8</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Simpsons</td>\n",
       "      <td>(1989– )</td>\n",
       "      <td>8.7</td>\n",
       "      <td>Animation, Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Series Name Release Years Ratings  \\\n",
       "0        Married... with Children   (1987–1997)     8.1   \n",
       "1  Star Trek: The Next Generation   (1987–1994)     8.7   \n",
       "2                        Seinfeld   (1989–1998)     8.9   \n",
       "3                      Twin Peaks   (1990–1991)     8.8   \n",
       "4                    The Simpsons      (1989– )     8.7   \n",
       "\n",
       "                                  Genre  \n",
       "0                    Comedy              \n",
       "1  Action, Adventure, Drama              \n",
       "2                    Comedy              \n",
       "3     Crime, Drama, Mystery              \n",
       "4         Animation, Comedy              "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10b8eda",
   "metadata": {},
   "source": [
    "## Classification  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5d2981a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nessesary libraries \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, precision_score, accuracy_score, classification_report, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c74fbe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Features'] = df['Series Name'] + ' ' + df['Release Years'] + ' ' + df['Ratings'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bd8072cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4\n",
      "\n",
      "Classification Report:\n",
      "                                           precision    recall  f1-score   support\n",
      "\n",
      "    Action, Adventure, Drama                   0.00      0.00      0.00         1\n",
      "        Action, Crime, Drama                   0.00      0.00      0.00         1\n",
      "    Adventure, Drama, Sci-Fi                   0.00      0.00      0.00         2\n",
      "Animation, Action, Adventure                   0.11      1.00      0.20         1\n",
      "   Animation, Action, Comedy                   0.00      0.00      0.00         1\n",
      "           Animation, Comedy                   0.00      0.00      0.00         3\n",
      "                      Comedy                   0.50      1.00      0.67         2\n",
      "               Comedy, Drama                   0.67      1.00      0.80         4\n",
      "             Comedy, Romance                   0.00      0.00      0.00         1\n",
      "       Crime, Drama, History                   0.00      0.00      0.00         1\n",
      "       Crime, Drama, Mystery                   1.00      1.00      1.00         1\n",
      "      Crime, Drama, Thriller                   0.00      0.00      0.00         1\n",
      "              Drama, Mystery                   0.00      0.00      0.00         1\n",
      "\n",
      "                                accuracy                           0.40        20\n",
      "                               macro avg       0.18      0.31      0.21        20\n",
      "                            weighted avg       0.24      0.40      0.29        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tetianabas/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tetianabas/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tetianabas/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Features'], df['Genre'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline with TF-IDF vectorizer and Multinomial Naive Bayes\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3791ad",
   "metadata": {},
   "source": [
    "The initial model trained on TF-IDF vectorized data with a Multinomial Naive Bayes classifier resulted in an accuracy of 0.4. Looking at the classification report, it's evident that the model performed poorly across various genres. The precision, recall, and f1-score values are low for most genres, indicating a lack of predictive power. The macro and weighted averages are also low, suggesting an overall weak model.\n",
    "\n",
    "The initial model used default hyperparameters. Given the diversity of genres and the complexity of language in TV show descriptions, fine-tuning hyperparameters is essential for improving model performance.GridSearchCV allows us to systematically search through a range of hyperparameters, finding the combination that maximizes performance. In this case, the tuned hyperparameters likely led to a more effective model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3b4cf456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "\n",
      "Classification Report:\n",
      "                                           precision    recall  f1-score   support\n",
      "\n",
      "    Action, Adventure, Drama                   1.00      1.00      1.00         1\n",
      "        Action, Crime, Drama                   0.33      1.00      0.50         1\n",
      "    Adventure, Drama, Sci-Fi                   0.00      0.00      0.00         2\n",
      "Animation, Action, Adventure                   0.33      1.00      0.50         1\n",
      "   Animation, Action, Comedy                   1.00      1.00      1.00         1\n",
      "           Animation, Comedy                   1.00      1.00      1.00         3\n",
      "                      Comedy                   1.00      1.00      1.00         2\n",
      "               Comedy, Drama                   1.00      0.50      0.67         4\n",
      "             Comedy, Romance                   1.00      1.00      1.00         1\n",
      "       Crime, Drama, History                   1.00      1.00      1.00         1\n",
      "       Crime, Drama, Mystery                   1.00      1.00      1.00         1\n",
      "      Crime, Drama, Thriller                   1.00      1.00      1.00         1\n",
      "              Drama, Mystery                   1.00      1.00      1.00         1\n",
      "\n",
      "                                accuracy                           0.80        20\n",
      "                               macro avg       0.82      0.88      0.82        20\n",
      "                            weighted avg       0.83      0.80      0.78        20\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 3 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 2 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tetianabas/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/tetianabas/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tetianabas/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tetianabas/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'tfidfvectorizer__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'multinomialnb__alpha': [0.1, 0.5, 1.0, 2.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f399216",
   "metadata": {},
   "source": [
    "A GridSearchCV approach was used to explore different hyperparameter combinations for the TF-IDF vectorizer and Multinomial Naive Bayes classifier. The best estimator from the grid search was then evaluated on the test set, resulting in an improved accuracy of 0.8 signaling a significant improvement in the model's ability to correctly predict TV show genres. The classification report for the improved model shows higher precision, recall, and f1-score values across various genres. The macro and weighted averages are also improved, indicating a more robust and reliable model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f8b92b",
   "metadata": {},
   "source": [
    "Understanding where the model makes mistakes can provide valuable insights into its decision-making process. Examining misclassifications helps identify patterns, genres that are challenging, or specific descriptions that lead to errors. If there are consistent patterns in the misclassifications, it can guide further model improvement efforts. For example, if certain genres are commonly confused, it might indicate a need for more diverse training data or a more complex model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e157667d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Label: Adventure, Drama, Sci-Fi             | Predicted Label: Animation, Action, Adventure            \n",
      "Text: Firefly (2002–2003) 9.0\n",
      "\n",
      "True Label: Comedy, Drama             | Predicted Label: Action, Crime, Drama            \n",
      "Text: Scrubs (2001–2010) 8.4\n",
      "\n",
      "True Label: Comedy, Drama             | Predicted Label: Action, Crime, Drama            \n",
      "Text: Scrubs (2001–2010) 8.4\n",
      "\n",
      "True Label: Adventure, Drama, Sci-Fi             | Predicted Label: Animation, Action, Adventure            \n",
      "Text: Firefly (2002–2003) 9.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "incorrect_predictions = X_test[y_pred != y_test]\n",
    "true_labels = y_test[y_pred != y_test]\n",
    "predicted_labels = y_pred[y_pred != y_test]\n",
    "for i in range(min(5, len(incorrect_predictions))):\n",
    "    print(f\"True Label: {true_labels.iloc[i]} | Predicted Label: {predicted_labels[i]}\")\n",
    "    print(f\"Text: {incorrect_predictions.iloc[i]}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabe8b0e",
   "metadata": {},
   "source": [
    "In Step A, the Multinomial Naive Bayes model with TF-IDF vectorization demonstrated limitations, especially in misclassifying genres like Adventure, Drama, Sci-Fi and Comedy, Drama. I will change the model to the randomforest model. Random Forests can handle non-linear relationships between features and labels, providing flexibility that may be lacking in a linear model like Naive Bayes. This could potentially address the misclassifications observed before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "eda6478b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Model Accuracy: 0.8\n",
      "\n",
      "Improved Model Classification Report:\n",
      "                                           precision    recall  f1-score   support\n",
      "\n",
      "    Action, Adventure, Drama                   1.00      1.00      1.00         1\n",
      "        Action, Crime, Drama                   0.20      1.00      0.33         1\n",
      "    Adventure, Drama, Sci-Fi                   0.00      0.00      0.00         2\n",
      "Animation, Action, Adventure                   1.00      1.00      1.00         1\n",
      "   Animation, Action, Comedy                   1.00      1.00      1.00         1\n",
      "           Animation, Comedy                   1.00      1.00      1.00         3\n",
      "                      Comedy                   1.00      1.00      1.00         2\n",
      "               Comedy, Drama                   1.00      0.50      0.67         4\n",
      "             Comedy, Romance                   1.00      1.00      1.00         1\n",
      "       Crime, Drama, History                   1.00      1.00      1.00         1\n",
      "       Crime, Drama, Mystery                   1.00      1.00      1.00         1\n",
      "      Crime, Drama, Thriller                   1.00      1.00      1.00         1\n",
      "              Drama, Mystery                   1.00      1.00      1.00         1\n",
      "\n",
      "                                accuracy                           0.80        20\n",
      "                               macro avg       0.86      0.88      0.85        20\n",
      "                            weighted avg       0.86      0.80      0.80        20\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 3 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 2 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tetianabas/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tetianabas/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tetianabas/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#i will use random forest classifier to improve the rsults \n",
    "model2 = make_pipeline(TfidfVectorizer(), RandomForestClassifier(n_estimators=100))\n",
    "model2.fit(X_train, y_train)\n",
    "y_pred_improved = model2.predict(X_test)\n",
    "\n",
    "accuracy_improved = accuracy_score(y_test, y_pred_improved)\n",
    "report_improved = classification_report(y_test, y_pred_improved)\n",
    "\n",
    "print(f\"Improved Model Accuracy: {accuracy_improved}\")\n",
    "print(\"\\nImproved Model Classification Report:\\n\", report_improved)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_improved))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea04ec8",
   "metadata": {},
   "source": [
    "Both the Random Forest model and the Grid Search-tuned Multinomial Naive Bayes model exhibit the same accuracy of 0.8, indicating that they correctly predicted the genre for 80% of the test data. In terms of macro and weighted average F1-scores, the Random Forest model outperforms the Grid Search-tuned Multinomial Naive Bayes model. The Random Forest model achieves higher scores in both metrics, indicating better overall precision, recall, and balance between precision and recall across different genres.The confusion matrices provide insights into the performance of each model. In the Random Forest model, the diagonal elements have higher values, indicating correct predictions for various genres. The Grid Search-tuned Multinomial Naive Bayes model, while achieving the same accuracy, has lower values on the diagonal, suggesting a less robust performance compared to the Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f232277b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
